{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UF6wIpDEr-6o"
      },
      "source": [
        "<h1>Modelo con transferencia de aprendizaje (VGG16) para OCT macular</h1>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "91rDjNzdiYoB"
      },
      "source": [
        "# Importación de librerías"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kNw516fHJg06"
      },
      "outputs": [],
      "source": [
        "# Importación de librerias\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "import sys\n",
        "import cv2 as cv\n",
        "import os\n",
        "import re\n",
        "import shutil\n",
        "from shutil import rmtree\n",
        "import keras\n",
        "from keras.models import load_model\n",
        "from keras.metrics import SensitivityAtSpecificity, Precision, Recall, SpecificityAtSensitivity\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras import optimizers\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dropout, Flatten, Dense, Activation\n",
        "from keras.layers import Convolution2D, MaxPooling2D\n",
        "from keras import backend as K\n",
        "from keras import applications\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import itertools\n",
        "from sklearn.metrics import classification_report\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NtGr1vYviYoD"
      },
      "source": [
        "# Listado de imagenes de cada directorio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "40ps97rMiYoD"
      },
      "outputs": [],
      "source": [
        "files_namesCNV = os.listdir(\"UNIDA/CNV\")\n",
        "files_namesDME = os.listdir(\"UNIDA/DME\")\n",
        "files_namesDRUSEN = os.listdir(\"UNIDA/DRUSEN\")\n",
        "files_namesNORMAL = os.listdir(\"UNIDA/NORMAL\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OGrJNQksiYoE"
      },
      "source": [
        "# Creación de arreglo con los listados de imagenes de cada clase"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BO7hGmRviYoE"
      },
      "outputs": [],
      "source": [
        "lectura = np.array([files_namesCNV,files_namesDME,files_namesDRUSEN,files_namesNORMAL])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z4TdXlD7iYoF"
      },
      "source": [
        "# Rutas de conjuntos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZIuRzb80iYoF"
      },
      "outputs": [],
      "source": [
        "rutain = ['UNIDA/CNV','UNIDA/DME','UNIDA/DRUSEN','UNIDA/NORMAL']\n",
        "rutaout = ['train/CNV','train/DME','train/DRUSEN','train/NORMAL']\n",
        "rutaoutVal = ['val/CNV','val/DME','val/DRUSEN','val/NORMAL']\n",
        "rutaoutTest = ['test/CNV','test/DME','test/DRUSEN','test/NORMAL']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NpoTJtdiWhDj"
      },
      "source": [
        "# Lista de variables para CNN y Kfold cross valitadion\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t9f6BFPKTGmd"
      },
      "outputs": [],
      "source": [
        "epocas = 55\n",
        "longitud, altura = 496, 496\n",
        "batch_size = 32\n",
        "filtrosConv1 = 256\n",
        "tamano_filtro1 = (3, 3)\n",
        "tamano_pool = (2, 2)\n",
        "clases = 4\n",
        "lr = 0.0001\n",
        "num_folds = 5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nOvZRJbFlnRY"
      },
      "source": [
        "# Función de generación números aleatorios"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dh4EsTlViYoG"
      },
      "outputs": [],
      "source": [
        "def semilla(total):\n",
        "    f=list(range(total))\n",
        "    orden=random.sample(f,total)\n",
        "    return orden"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Buuys7wOiYoH"
      },
      "source": [
        "# Ruta de directorios validación cruzada"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BySBWnUiiYoH"
      },
      "outputs": [],
      "source": [
        "# Cargue de las imagenes..Ruta\n",
        "rutatrain = ['K1/train/',\n",
        "        'K2/train/',\n",
        "        'K3/train/',\n",
        "        'K4/train/',\n",
        "        'K5/train/']\n",
        "\n",
        "rutaval = ['K1/val/',\n",
        "        'K2/val/',\n",
        "        'K3/val/',\n",
        "        'K4/val/',\n",
        "        'K5/val/']\n",
        "\n",
        "rutatest = ['K1/test/',\n",
        "        'K2/test/',\n",
        "        'K3/test/',\n",
        "        'K4/test/',\n",
        "        'K5/test/']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2w3DguVZasmv"
      },
      "source": [
        "# Activación de parámetro de multiproceso"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "94L76kg9fS4-"
      },
      "outputs": [],
      "source": [
        "import multiprocessing\n",
        "manager = multiprocessing.Manager()\n",
        "queue = manager.Queue(maxsize=80000)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8AH9s7Zh7fp0"
      },
      "source": [
        "# Creación de vectores para acumular las métricas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yyb_PVDT8qXB"
      },
      "outputs": [],
      "source": [
        "# Vectores de acumulación\n",
        "acc_per_fold = []\n",
        "loss_per_fold = []\n",
        "se_per_fold = []\n",
        "sp_per_fold = []\n",
        "rc_per_fold = []\n",
        "pc_per_fold = []"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dJxtI3NV70qa"
      },
      "source": [
        "# Creación de modelo de transferencia de aprendizaje"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UQkEkeS5vSSO"
      },
      "outputs": [],
      "source": [
        "# Generación del modelo\n",
        "def modelo():\n",
        "    vgg=applications.vgg16.VGG16(weights='imagenet',\n",
        "                    include_top=False,\n",
        "                    input_shape=(496, 496, 3)) # carga el modelo VGG16 en la variable vgg\n",
        "    cnn=Sequential()               # crea un modelo vacio del tipo secuencial\n",
        "    for layer in vgg.layers:       # Transfiere las capas de vgg al modelo secuencial vacio cnn\n",
        "        cnn.add(layer)\n",
        "    cnn.pop()                      # Elimina la última capa de predicción\n",
        "    for layer in cnn.layers:       # Recorre y hace que no vuelvan a entrenar\n",
        "        layer.trainable=False\n",
        "      # Se adicionan capas no entrenadas\n",
        "    cnn.add(MaxPooling2D(pool_size=tamano_pool))\n",
        "    cnn.add(Convolution2D(filtrosConv1, tamano_filtro1, padding =\"same\", activation='relu'))\n",
        "    cnn.add(Convolution2D(filtrosConv1, tamano_filtro1, padding =\"same\", activation='relu'))\n",
        "    cnn.add(Convolution2D(filtrosConv1, tamano_filtro1, padding =\"same\", activation='relu'))\n",
        "    cnn.add(MaxPooling2D(pool_size=tamano_pool))\n",
        "    cnn.add(Flatten())\n",
        "    cnn.add(Dense(256, activation='relu'))\n",
        "    cnn.add(Dropout(0.5))\n",
        "    cnn.add(Dense(clases, activation='softmax')) # agrega capa de 4 neuronas para las 4 clases a clasificar\n",
        "\n",
        "    return cnn\n",
        "\n",
        "K.clear_session()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ol1oVm0Fbs91"
      },
      "source": [
        "# visualización del modelo y sus parámetros"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "b4Xd7dSTvVLU",
        "outputId": "6d21f63e-339c-4e6b-ad26-7edf9e989a5b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " block1_conv1 (Conv2D)       (None, 496, 496, 64)      1792      \n",
            "                                                                 \n",
            " block1_conv2 (Conv2D)       (None, 496, 496, 64)      36928     \n",
            "                                                                 \n",
            " block1_pool (MaxPooling2D)  (None, 248, 248, 64)      0         \n",
            "                                                                 \n",
            " block2_conv1 (Conv2D)       (None, 248, 248, 128)     73856     \n",
            "                                                                 \n",
            " block2_conv2 (Conv2D)       (None, 248, 248, 128)     147584    \n",
            "                                                                 \n",
            " block2_pool (MaxPooling2D)  (None, 124, 124, 128)     0         \n",
            "                                                                 \n",
            " block3_conv1 (Conv2D)       (None, 124, 124, 256)     295168    \n",
            "                                                                 \n",
            " block3_conv2 (Conv2D)       (None, 124, 124, 256)     590080    \n",
            "                                                                 \n",
            " block3_conv3 (Conv2D)       (None, 124, 124, 256)     590080    \n",
            "                                                                 \n",
            " block3_pool (MaxPooling2D)  (None, 62, 62, 256)       0         \n",
            "                                                                 \n",
            " block4_conv1 (Conv2D)       (None, 62, 62, 512)       1180160   \n",
            "                                                                 \n",
            " block4_conv2 (Conv2D)       (None, 62, 62, 512)       2359808   \n",
            "                                                                 \n",
            " block4_conv3 (Conv2D)       (None, 62, 62, 512)       2359808   \n",
            "                                                                 \n",
            " block4_pool (MaxPooling2D)  (None, 31, 31, 512)       0         \n",
            "                                                                 \n",
            " block5_conv1 (Conv2D)       (None, 31, 31, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv2 (Conv2D)       (None, 31, 31, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv3 (Conv2D)       (None, 31, 31, 512)       2359808   \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 15, 15, 512)      0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d (Conv2D)             (None, 15, 15, 256)       1179904   \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 15, 15, 256)       590080    \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 15, 15, 256)       590080    \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 7, 7, 256)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 12544)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 256)               3211520   \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 256)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 4)                 1028      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 20,287,300\n",
            "Trainable params: 5,572,612\n",
            "Non-trainable params: 14,714,688\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "cnn=modelo()\n",
        "cnn.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zxYZuUDFb_hS"
      },
      "source": [
        "# Funciones de creación y eliminación de directorios"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q3jSWv6tiYoK"
      },
      "outputs": [],
      "source": [
        "def eliminar(directorio):\n",
        "    estado=os.path.exists(directorio)\n",
        "    if estado == True:\n",
        "        rmtree(directorio)\n",
        "\n",
        "def crear(Rct,Rcv,Rcp):\n",
        "    Rt=Rct\n",
        "    Rv=Rcv\n",
        "    Rp=Rcp\n",
        "    for i in range(0,5):\n",
        "        os.makedirs(Rt[i]+'/CNV', exist_ok = True)\n",
        "        os.makedirs(Rt[i]+'/DME', exist_ok = True)\n",
        "        os.makedirs(Rt[i]+'/DRUSEN', exist_ok = True)\n",
        "        os.makedirs(Rt[i]+'/NORMAL', exist_ok = True)\n",
        "        os.makedirs(Rv[i]+'/CNV', exist_ok = True)\n",
        "        os.makedirs(Rv[i]+'/DME', exist_ok = True)\n",
        "        os.makedirs(Rv[i]+'/DRUSEN', exist_ok = True)\n",
        "        os.makedirs(Rv[i]+'/NORMAL', exist_ok = True)\n",
        "        os.makedirs(Rp[i]+'/CNV', exist_ok = True)\n",
        "        os.makedirs(Rp[i]+'/DME', exist_ok = True)\n",
        "        os.makedirs(Rp[i]+'/DRUSEN', exist_ok = True)\n",
        "        os.makedirs(Rp[i]+'/NORMAL', exist_ok = True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eyCvFXxEiYoK"
      },
      "source": [
        "# Arraglo para ruta de k-fold"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E0rMbIRXiYoK"
      },
      "outputs": [],
      "source": [
        "rutak=[\"K1\",\"K2\",\"K3\",\"K4\",\"K5\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a4udNzUKiYoK"
      },
      "source": [
        "# Función para graficar matriz de confusión"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ISzqFTXTxejM"
      },
      "outputs": [],
      "source": [
        "def plot_confusion_matrix(cm,\n",
        "                          target_names,\n",
        "                          title='Confusion matrix',\n",
        "                          cmap=None,\n",
        "                          normalize=True):\n",
        "    \"\"\"\n",
        "    given a sklearn confusion matrix (cm), make a nice plot\n",
        "\n",
        "    Arguments\n",
        "    ---------\n",
        "    cm:           confusion matrix from sklearn.metrics.confusion_matrix\n",
        "\n",
        "    target_names: given classification classes such as [0, 1, 2]\n",
        "                  the class names, for example: ['high', 'medium', 'low']\n",
        "\n",
        "    title:        the text to display at the top of the matrix\n",
        "\n",
        "    cmap:         the gradient of the values displayed from matplotlib.pyplot.cm\n",
        "                  see http://matplotlib.org/examples/color/colormaps_reference.html\n",
        "                  plt.get_cmap('jet') or plt.cm.Blues\n",
        "\n",
        "    normalize:    If False, plot the raw numbers\n",
        "                  If True, plot the proportions\n",
        "\n",
        "    Usage\n",
        "    -----\n",
        "    plot_confusion_matrix(cm           = cm,                  # confusion matrix created by\n",
        "                                                              # sklearn.metrics.confusion_matrix\n",
        "                          normalize    = True,                # show proportions\n",
        "                          target_names = y_labels_vals,       # list of names of the classes\n",
        "                          title        = best_estimator_name) # title of graph\n",
        "\n",
        "    Citiation\n",
        "    ---------\n",
        "    http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\n",
        "\n",
        "    \"\"\"\n",
        "    import matplotlib.pyplot as plt\n",
        "    import numpy as np\n",
        "    import itertools\n",
        "\n",
        "    accuracy = np.trace(cm) / float(np.sum(cm))\n",
        "    misclass = 1 - accuracy\n",
        "\n",
        "    if cmap is None:\n",
        "        cmap = plt.get_cmap('Blues')\n",
        "\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "\n",
        "    if target_names is not None:\n",
        "        tick_marks = np.arange(len(target_names))\n",
        "        plt.xticks(tick_marks, target_names, rotation=45)\n",
        "        plt.yticks(tick_marks, target_names)\n",
        "\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "\n",
        "\n",
        "    thresh = cm.max() / 1.5 if normalize else cm.max() / 2\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        if normalize:\n",
        "            plt.text(j, i, \"{:0.4f}\".format(cm[i, j]),\n",
        "                     horizontalalignment=\"center\",\n",
        "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "        else:\n",
        "            plt.text(j, i, \"{:,}\".format(cm[i, j]),\n",
        "                     horizontalalignment=\"center\",\n",
        "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label\\naccuracy={:0.4f}; misclass={:0.4f}'.format(accuracy, misclass))\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9BhfT_4ZiYoL"
      },
      "source": [
        "# Montecarlo y K-fold"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PRX6gFvHqslP"
      },
      "outputs": [],
      "source": [
        "# Montecarlo\n",
        "for m in range(1,11):\n",
        "    aleatorios=semilla(8616)\n",
        "\n",
        "    kf1=aleatorios[0:1551]\n",
        "    kf2=aleatorios[1551:3102]\n",
        "    kf3=aleatorios[3102:4653]\n",
        "    kf4=aleatorios[4653:6204]\n",
        "    kf5=aleatorios[6204:7755]\n",
        "    K=np.array([kf1,kf2,kf3,kf4,kf5])\n",
        "    t1=aleatorios[1551:7755]\n",
        "    t2=np.concatenate((kf1, aleatorios[3102:7755]))\n",
        "    t3=np.concatenate((aleatorios[0:3102], aleatorios[4653:7755]))\n",
        "    t4=np.concatenate((aleatorios[0:4653], aleatorios[6204:7755]))\n",
        "    t5=aleatorios[0:6204]\n",
        "    tk=np.array([t1,t2,t3,t4,t5])\n",
        "\n",
        "    # Eliminación y creación de directorios para k-fold\n",
        "    for g in range(0,5):\n",
        "        eliminar(rutak[g])\n",
        "    crear(rutatrain,rutaval,rutatest)\n",
        "\n",
        "    # Creación de conjunto de entrenamiento, validación y prueba\n",
        "    for j in range(len(rutain)):\n",
        "        files_names=lectura[j]\n",
        "        for p in range(0,5):\n",
        "                for t in K[p]:\n",
        "                    image_path = str(rutain[j]) + \"/\" + str(files_names[t])\n",
        "                    nombre=str(files_names[t]).rsplit('.', 1)[0]\n",
        "                    outputk1=\"K\"+str(p+1)+\"/\"+rutaoutVal[j]+\"/\"+nombre+\".jpeg\"\n",
        "                    imagen = cv.imread(image_path)\n",
        "                    cv.imwrite(outputk1,imagen)\n",
        "                for h in tk[p]:\n",
        "                    image_path = str(rutain[j]) + \"/\" + str(files_names[aleatorios[h]])\n",
        "                    nombre=str(files_names[aleatorios[h]]).rsplit('.', 1)[0]\n",
        "                    outputTrain=\"K\"+str(p+1)+\"/\"+rutaout[j]+\"/\"+nombre+\".jpeg\"\n",
        "                    imagen = cv.imread(image_path)\n",
        "                    cv.imwrite(outputTrain,imagen)\n",
        "                for k in range(round(len(aleatorios)*0.9),len(aleatorios)):\n",
        "                    image_path = str(rutain[j]) + \"/\" + str(files_names[aleatorios[k]])\n",
        "                    nombre=str(files_names[aleatorios[k]]).rsplit('.', 1)[0]\n",
        "                    outputTest=\"K\"+str(p+1)+\"/\"+rutaoutTest[j]+\"/\"+nombre+\".jpeg\"\n",
        "                    imagen = cv.imread(image_path)\n",
        "                    cv.imwrite(outputTest,imagen)\n",
        "        print(\"clase \"+str(j) +\" terminada\")\n",
        "    print(\"Conjuntos train, val y test fueron creados\")\n",
        "\n",
        "    # K-fold Cross Validation\n",
        "    ruta=0\n",
        "    for fold_no in range(1,num_folds+1):\n",
        "\n",
        "        #Preparamos nuestras imagenes de entrenamiento con diferentes transformaciones para generalizar el aprendizaje\n",
        "        entrenamiento_datagen = ImageDataGenerator(\n",
        "            rescale=1. / 255,\n",
        "            shear_range=0.2,\n",
        "            zoom_range=0.2,\n",
        "            horizontal_flip=True)\n",
        "\n",
        "        #Preparamos nuestras imagenes de validación\n",
        "        valid_datagen = ImageDataGenerator(rescale=1. / 255)\n",
        "\n",
        "        for i in range(1,3):\n",
        "            #Se leen las imagenes de entrenamiento del directorio\n",
        "            entrenamiento_generador = entrenamiento_datagen.flow_from_directory(\n",
        "                rutatrain[ruta],\n",
        "                target_size=(altura, longitud),\n",
        "                batch_size=batch_size,\n",
        "                class_mode='categorical')\n",
        "\n",
        "            #Se leen las imagenes de validación del directorio\n",
        "            validacion_generador = valid_datagen.flow_from_directory(\n",
        "                rutaval[ruta],\n",
        "                target_size=(altura, longitud),\n",
        "                batch_size=batch_size,\n",
        "                class_mode='categorical')\n",
        "\n",
        "        #Se generan los pasos de entrenamiento y validación\n",
        "        pasos = entrenamiento_generador.n // (entrenamiento_generador.batch_size*7)\n",
        "        validation_steps = validacion_generador.n // (validacion_generador.batch_size*5)\n",
        "\n",
        "        #Se compila el modelo\n",
        "        cnn=modelo()\n",
        "        #cnn.summary()\n",
        "        cnn.compile(optimizer = 'adam',\n",
        "        loss='categorical_crossentropy',\n",
        "        metrics=['accuracy','mse',Recall(),Precision()])\n",
        "\n",
        "\n",
        "        # Genera impresión de cada iteración de k fold\n",
        "        print('------------------------------------------------------------------------')\n",
        "        print(f'Entrenamiento para K-fold {fold_no} ...')\n",
        "\n",
        "        # Entrenamiento del modelo\n",
        "        history = cnn.fit(\n",
        "            entrenamiento_generador,\n",
        "            steps_per_epoch=pasos,\n",
        "            epochs=epocas,\n",
        "            validation_data=validacion_generador,\n",
        "            validation_steps=validation_steps)\n",
        "\n",
        "        # Guarda el modelo y pesos entrenados en una carpeta por cada iteración\n",
        "        target_dir = 'modelos/'+str(m)+\"/K\"+str(fold_no)\n",
        "        if not os.path.exists(target_dir):\n",
        "            os.mkdir(target_dir)\n",
        "            cnn.save(target_dir+'/K'+str(fold_no)+'.h5')\n",
        "            cnn.save_weights(target_dir+'/Kp'+str(fold_no)+'.h5')\n",
        "\n",
        "\n",
        "        # Generación de métricas\n",
        "        scores = cnn.evaluate(validacion_generador, steps=194, verbose=2, callbacks=None)\n",
        "        print(f'Score para fold {fold_no}: {cnn.metrics_names[0]} of {scores[0]}; {cnn.metrics_names[1]} of {scores[1]*100}%; {cnn.metrics_names[3]} of {scores[3]*100}%; {cnn.metrics_names[4]} of {scores[4]*100}%')\n",
        "        acc_per_fold.append(scores[1] * 100)\n",
        "        loss_per_fold.append(scores[0])\n",
        "        se_per_fold.append(scores[3])\n",
        "        sp_per_fold.append(scores[4])\n",
        "\n",
        "        #Confution Matrix and Classification Report\n",
        "        Y_pred = cnn.predict(validacion_generador)\n",
        "        y_pred = np.argmax(Y_pred, axis=1)\n",
        "\n",
        "        print('******** Confusion Matrix para K-fold '+str(fold_no)+ '********')\n",
        "        cm=confusion_matrix(validacion_generador.classes, y_pred)\n",
        "        print(cm)\n",
        "        print('Classification Report')\n",
        "        target_names = ['CNV', 'DME', 'DRUSSEN', 'NORMAL']\n",
        "        print(classification_report(validacion_generador.classes, y_pred, target_names=target_names))\n",
        "\n",
        "        plot_confusion_matrix(cm,\n",
        "        normalize    = False,\n",
        "        target_names = ['CNV', 'DME', 'DRUSSEN', 'NORMAL'],\n",
        "        title        = \"Confusion Matrix\")\n",
        "        plt.savefig(target_dir+'/cm'+str(fold_no)+'.svg')\n",
        "\n",
        "        # Visualización history o proceso de entrenamiento\n",
        "\n",
        "        # Plot history: Loss\n",
        "        plt.figure(figsize=(15,7))\n",
        "        plt.subplot(121)\n",
        "        plt.plot(history.history['loss'])\n",
        "        plt.plot(history.history['val_loss'])\n",
        "        plt.title('Validation loss history')\n",
        "        plt.ylabel('Loss value')\n",
        "        plt.xlabel('No. epoch')\n",
        "        plt.legend(['loss', 'val_loss'], loc='upper right')\n",
        "        plt.grid(linestyle=':')\n",
        "\n",
        "        # Plot history: Accuracy\n",
        "        plt.subplot(122)\n",
        "        plt.plot(history.history['accuracy'])\n",
        "        plt.plot(history.history['val_accuracy'])\n",
        "        plt.title('Validation accuracy history')\n",
        "        plt.ylabel('Accuracy value')\n",
        "        plt.xlabel('No. epoch')\n",
        "        plt.legend(['accuracy', 'Val_accuracy'], loc='upper left')\n",
        "        plt.grid(linestyle=':')\n",
        "        plt.show()\n",
        "        plt.savefig(target_dir+\"/TrainVsVal\"+str(fold_no)+\".svg\", format=\"svg\")\n",
        "\n",
        "\n",
        "        # Plot history: loss vs Accuracy\n",
        "        plt.figure(figsize=(8, 7))\n",
        "        plt.plot(history.history['val_loss'])\n",
        "        plt.plot(history.history['val_accuracy'])\n",
        "        plt.title('Validation loss and accuracy history')\n",
        "        plt.xlabel('No. epoch')\n",
        "        plt.ylabel('Loss value')\n",
        "        plt.legend(['val_loss', 'val_accuracy'], loc='best')\n",
        "        plt.grid(linestyle=':')\n",
        "        plt.twinx()\n",
        "        plt.ylabel('Accuracy value')\n",
        "        plt.show()\n",
        "        plt.savefig(target_dir+\"/ValVsVal\"+str(fold_no)+\".svg\", format=\"svg\")\n",
        "\n",
        "\n",
        "        #Preparamos nuestras imagenes de test\n",
        "        test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
        "        #Se leen las imagenes de test del directorio\n",
        "        test_generador = test_datagen.flow_from_directory(\n",
        "            data_test,\n",
        "            target_size=(altura, longitud),\n",
        "            batch_size=batch_size,\n",
        "            class_mode='categorical',\n",
        "            shuffle=False)\n",
        "\n",
        "        #predicción conjunto test\n",
        "        t_pred = cnn.predict(test_generador)\n",
        "        t_pred = np.argmax(t_pred, axis=1)\n",
        "\n",
        "        print('Confusion Matrix')\n",
        "        cm=confusion_matrix(test_generador.classes, t_pred)\n",
        "        print(cm)\n",
        "        print('Classification Report')\n",
        "        target_names = ['CNV', 'DME', 'DRUSSEN', 'NORMAL']\n",
        "        print(classification_report(test_generador.classes, t_pred, target_names=target_names))\n",
        "\n",
        "        plot_confusion_matrix(cm,\n",
        "        normalize    = False,\n",
        "        target_names = ['CNV', 'DME', 'DRUSSEN', 'NORMAL'],\n",
        "        title        = \"Confusion Matrix\")\n",
        "        plt.savefig(target_dir+\"/cmtest\"+str(fold_no)+\".svg\", format=\"svg\")\n",
        "\n",
        "\n",
        "    # Promedio de los score\n",
        "    print('------------------------------------------------------------------------')\n",
        "    print('Score for fold')\n",
        "    for i in range(0, len(acc_per_fold)-1):\n",
        "        print('------------------------------------------------------------------------')\n",
        "        print(f'> Fold {i+1} - Loss: {loss_per_fold[i]} - Accuracy: {acc_per_fold[i]}% - Recall: {rc_per_fold[i]}% - Precision: {pc_per_fold[i]}%')\n",
        "        print('------------------------------------------------------------------------')\n",
        "\n",
        "    # Tabla de los promedios de métricas de cada iteración de la validación\n",
        "    print('Average scores for all folds:')\n",
        "    print(f'> Accuracy: {np.mean(acc_per_fold)} (+- {np.std(acc_per_fold)})')\n",
        "    print(f'> Loss: {np.mean(loss_per_fold)}')\n",
        "    print(f'> Recall: {np.mean(rc_per_fold)} (+- {np.std(rc_per_fold)})')\n",
        "    print(f'> Precision: {np.mean(pc_per_fold)} (+- {np.std(pc_per_fold)})')\n",
        "    print('------------------------------------------------------------------------')\n",
        "    print('Montecarlo '+str(m))\n",
        "\n",
        "print(\"Entrenamiento y prueba mediante montecarlo=10 y validación cruzada=5 finalizó\")\n",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7B05wW2FlBGg"
      },
      "source": [
        "# Cargue del modelo para predicción independinete del montecarlo (prueba)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kqOOHUmD3oX0"
      },
      "outputs": [],
      "source": [
        "# Carga modelo\n",
        "modelo = '/content/Drive/My Drive/IA/Proyectos/modelo/KV7/K2.h5'\n",
        "pesos_modelo = '/content/Drive/My Drive/IA/Proyectos/modelo/KV7/Kp2.h5'\n",
        "cnn = load_model(modelo)\n",
        "cnn.load_weights(pesos_modelo)\n",
        "#cnn.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yJRO8pcL0x4f"
      },
      "source": [
        "# Ruta de imagenes de test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DkDaM9WvsRPt"
      },
      "outputs": [],
      "source": [
        "data_test = '/content/Drive/My Drive/IA/Proyectos/test/'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1-yW-z3j38Jv"
      },
      "source": [
        "# Preparación de imágenes de test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2-pu-YMozwiR",
        "outputId": "1630bebb-6a65-46b9-deb8-11bfd74a25fd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 3448 images belonging to 4 classes.\n"
          ]
        }
      ],
      "source": [
        "#Preparamos nuestras imagenes de test\n",
        "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
        "#Se leen las imagenes de test del directorio\n",
        "test_generador = test_datagen.flow_from_directory(\n",
        "  data_test,\n",
        "  target_size=(altura, longitud),\n",
        "  batch_size=batch_size,\n",
        "  class_mode='categorical',\n",
        "  shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BT08ANlU7WS3"
      },
      "source": [
        "# Cálculo de la predicción con conjunto test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7BNN90iM2Lhz"
      },
      "outputs": [],
      "source": [
        "#predicción conjunto test\n",
        "t_pred = cnn.predict(test_generador)\n",
        "t_pred = np.argmax(t_pred, axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xjIfgQC27xR6"
      },
      "source": [
        "# Matriz de confusión y reporte de métricas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-TLqrd8P2hx1"
      },
      "outputs": [],
      "source": [
        "print('Confusion Matrix')\n",
        "cm=confusion_matrix(test_generador.classes, t_pred)\n",
        "print(cm)\n",
        "print('Classification Report')\n",
        "target_names = ['CNV', 'DME', 'DRUSSEN', 'NORMAL']\n",
        "print(classification_report(test_generador.classes, t_pred, target_names=target_names))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9bM6lpGD74-G"
      },
      "source": [
        "# Gráfica de la matriz de confusión"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AAhONco3J1Jd"
      },
      "outputs": [],
      "source": [
        "plot_confusion_matrix(cm,\n",
        "normalize    = False,\n",
        "target_names = ['CNV', 'DME', 'DRUSSEN', 'NORMAL'],\n",
        "title        = \"Confusion Matrix\")\n",
        "plt.savefig('/content/Drive/My Drive/IA/Proyectos/modelo/cmtest.svg')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}